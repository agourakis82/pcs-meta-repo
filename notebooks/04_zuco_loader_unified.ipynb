{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "170156e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.11\n",
      "pandas 2.3.2\n",
      "numpy 1.26.4\n",
      "joblib 1.5.2\n",
      "scipy 1.13.1\n",
      "h5py 3.14.0\n",
      "Loaded zuco_loader from /home/agourakis82/workspace/pcs-meta-repo/tools/zuco_loader.py\n",
      "Loaded zuco_loader from /home/agourakis82/workspace/pcs-meta-repo/tools/zuco_loader.py\n"
     ]
    }
   ],
   "source": [
    "# Setup: install optional deps and print versions, then import loader\n",
    "import sys, subprocess, importlib, platform\n",
    "from pathlib import Path\n",
    "\n",
    "REQS = ['pandas', 'numpy', 'joblib', 'scipy', 'h5py']\n",
    "for pkg in REQS:\n",
    "    try:\n",
    "        importlib.import_module(pkg)\n",
    "    except Exception:\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '--quiet', pkg], check=False)\n",
    "\n",
    "import pandas as pd, numpy as np\n",
    "import joblib, scipy, h5py\n",
    "print(f\"Python {platform.python_version()}\")\n",
    "print(\"pandas\", pd.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"joblib\", joblib.__version__)\n",
    "print(\"scipy\", scipy.__version__)\n",
    "print(\"h5py\", h5py.__version__)\n",
    "\n",
    "# Paths (relative to repo)\n",
    "BASE = Path.cwd()\n",
    "RAW = BASE.parent / 'data' / 'raw_public' / 'zuco'\n",
    "PROC = BASE.parent / 'data' / 'processed'\n",
    "RPTS = BASE / 'reports'\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "RPTS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Import loader\n",
    "import importlib.util, sys\n",
    "loader_path = BASE.parent / 'tools' / 'zuco_loader.py'\n",
    "spec = importlib.util.spec_from_file_location('zuco_loader', loader_path)\n",
    "zuco_loader = importlib.util.module_from_spec(spec)\n",
    "sys.modules['zuco_loader'] = zuco_loader\n",
    "assert spec and spec.loader\n",
    "spec.loader.exec_module(zuco_loader)\n",
    "print(\"Loaded zuco_loader from\", loader_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ce43fe",
   "metadata": {},
   "source": [
    "### Discover files under data/raw_public/zuco/{v1,v2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0fb3f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'v1': {'et_mat': 202, 'eeg_tabular': 4}, 'v2': {'et_mat': 133, 'eeg_tabular': 0}}\n",
      "\n",
      "[v1] ET .mat files (up to 5 shown):\n",
      " - v1/Preprocessed/ZAB/ZAB_TSR1_corrected_ET.mat\n",
      " - v1/Preprocessed/ZAB/ZAB_TSR2_corrected_ET.mat\n",
      " - v1/Preprocessed/ZAB/ZAB_TSR3_corrected_ET.mat\n",
      " - v1/Preprocessed/ZAB/ZAB_TSR4_corrected_ET.mat\n",
      " - v1/Preprocessed/ZAB/ZAB_TSR5_corrected_ET.mat\n",
      "[v1] EEG tabular files (up to 5 shown):\n",
      " - v1/Preprocessed/relations_task_specific.csv\n",
      " - v1/task1- SR/Preprocessed/sentiment_normal_reading.csv\n",
      " - v1/task1- SR/Raw data/sentiment_normal_reading.csv\n",
      " - v1/task3 - TSR/Raw data/relations_task_specific.csv\n",
      "\n",
      "[v2] ET .mat files (up to 5 shown):\n",
      " - v2/task2 - TSR/Preprocessed/YAC/YAC_TSR1_corrected_ET.mat\n",
      " - v2/task2 - TSR/Preprocessed/YAC/YAC_TSR2_corrected_ET.mat\n",
      " - v2/task2 - TSR/Preprocessed/YAC/YAC_TSR3_corrected_ET.mat\n",
      " - v2/task2 - TSR/Preprocessed/YAC/YAC_TSR4_corrected_ET.mat\n",
      " - v2/task2 - TSR/Preprocessed/YAC/YAC_TSR5_corrected_ET.mat\n",
      "[v2] EEG tabular files (up to 5 shown):\n"
     ]
    }
   ],
   "source": [
    "disc = zuco_loader.discover(RAW)\n",
    "print({k: {'et_mat': len(v.et_mat), 'eeg_tabular': len(v.eeg_tabular)} for k,v in disc.items()})\n",
    "for ver, fd in disc.items():\n",
    "    print(f\"\\n[{ver}] ET .mat files (up to 5 shown):\")\n",
    "    for p in fd.et_mat[:5]: print(\" -\", p.relative_to(RAW))\n",
    "    print(f\"[{ver}] EEG tabular files (up to 5 shown):\")\n",
    "    for p in fd.eeg_tabular[:5]: print(\" -\", p.relative_to(RAW))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b800fbe",
   "metadata": {},
   "source": [
    "### Load ET and EEG tables and aggregate EEG per canonical keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ed9cc69",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "spec not found for the module 'zuco_loader'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimportlib\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m zuco_loader = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzuco_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m df_et = zuco_loader.load_et(RAW, n_jobs=\u001b[32m1\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mET rows:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_et))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/lib/python3.12/importlib/__init__.py:130\u001b[39m, in \u001b[36mreload\u001b[39m\u001b[34m(module)\u001b[39m\n\u001b[32m    128\u001b[39m spec = module.__spec__ = _bootstrap._find_spec(name, pkgpath, target)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mspec not found for the module \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m, name=name)\n\u001b[32m    131\u001b[39m _bootstrap._exec(spec, module)\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# The module may have replaced itself in sys.modules!\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: spec not found for the module 'zuco_loader'"
     ]
    }
   ],
   "source": [
    "import importlib, sys\n",
    "# Ensure zuco_loader has a proper spec before reload\n",
    "try:\n",
    "    zuco_loader\n",
    "except NameError:\n",
    "    import importlib.util\n",
    "    loader_path = BASE.parent / 'tools' / 'zuco_loader.py'\n",
    "    spec = importlib.util.spec_from_file_location('zuco_loader', loader_path)\n",
    "    zuco_loader = importlib.util.module_from_spec(spec)\n",
    "    sys.modules['zuco_loader'] = zuco_loader\n",
    "    assert spec and spec.loader\n",
    "    spec.loader.exec_module(zuco_loader)\n",
    "else:\n",
    "    if getattr(zuco_loader, '__spec__', None) is None:\n",
    "        import importlib.util\n",
    "        loader_path = BASE.parent / 'tools' / 'zuco_loader.py'\n",
    "        spec = importlib.util.spec_from_file_location('zuco_loader', loader_path)\n",
    "        zuco_loader.__spec__ = spec\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import importlib\n",
    "zuco_loader = importlib.reload(zuco_loader)\n",
    "\n",
    "df_et = zuco_loader.load_et(RAW, n_jobs=1)\n",
    "print(\"ET rows:\", len(df_et))\n",
    "\n",
    "# Load and aggregate EEG\n",
    "agg_eeg = zuco_loader.load_eeg(RAW)\n",
    "print(\"EEG rows (aggregated):\", len(agg_eeg))\n",
    "\n",
    "# Basic validations\n",
    "required_keys = ['Dataset','Task','Subject','SentenceID','w_pos','token_norm']\n",
    "for name, df in [('ET', df_et), ('EEG', agg_eeg)]:\n",
    "    missing = [c for c in required_keys if c not in df.columns]\n",
    "    if missing:\n",
    "        print(f\"WARN: {name} missing columns: {missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c8dfff",
   "metadata": {},
   "source": [
    "### Merge ET + EEG and write outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d52e6e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/agourakis82/workspace/pcs-meta-repo/data/processed/zuco_aligned.csv\n",
      "QA saved: /home/agourakis82/workspace/pcs-meta-repo/notebooks/reports/zuco_loader_qa.json\n",
      "\n",
      "--- Preview (10 rows) ---\n",
      "  Dataset Task Subject  SentenceID  w_pos token token_norm           FFD  \\\n",
      "0      v1  TSR     ZAB           1      1  None       None  1.402865e+14   \n",
      "1      v1  TSR     ZAB           1      2  None       None  1.402865e+14   \n",
      "2      v1  TSR     ZAB           1      3  None       None  1.402865e+14   \n",
      "3      v1  TSR     ZAB           1      4  None       None  1.402865e+14   \n",
      "4      v1  TSR     ZAB           1      5  None       None  1.402865e+14   \n",
      "5      v1  TSR     ZAB           1      6  None       None  1.402865e+14   \n",
      "6      v1  TSR     ZAB           1      7  None       None  1.402865e+14   \n",
      "7      v1  TSR     ZAB           1      8  None       None  1.402865e+14   \n",
      "8      v1  TSR     ZAB           1      9  None       None  1.402865e+14   \n",
      "9      v1  TSR     ZAB           1     10  None       None  1.402865e+14   \n",
      "\n",
      "             GD           TRT  GPT  theta1  alpha1  beta1  gamma1  \n",
      "0  2.244584e+15  2.384871e+15  NaN     NaN     NaN    NaN     NaN  \n",
      "1  7.014326e+14  8.417191e+14  NaN     NaN     NaN    NaN     NaN  \n",
      "2  2.104298e+15  2.244584e+15  NaN     NaN     NaN    NaN     NaN  \n",
      "3  1.823725e+15  1.964011e+15  NaN     NaN     NaN    NaN     NaN  \n",
      "4  2.104298e+15  2.244584e+15  NaN     NaN     NaN    NaN     NaN  \n",
      "5  1.823725e+15  1.964011e+15  NaN     NaN     NaN    NaN     NaN  \n",
      "6  8.417191e+14  9.820056e+14  NaN     NaN     NaN    NaN     NaN  \n",
      "7  1.402865e+15  1.543152e+15  NaN     NaN     NaN    NaN     NaN  \n",
      "8  8.417191e+14  9.820056e+14  NaN     NaN     NaN    NaN     NaN  \n",
      "9  2.384871e+15  2.525157e+15  NaN     NaN     NaN    NaN     NaN  \n",
      "\n",
      "--- QA Summary ---\n",
      "{\n",
      "  \"rows\": 1129826,\n",
      "  \"subjects\": 30,\n",
      "  \"by_dataset\": {\n",
      "    \"v1\": 971936,\n",
      "    \"v2\": 157890\n",
      "  },\n",
      "  \"by_task\": {\n",
      "    \"\": 85548,\n",
      "    \"TSR\": 1044278\n",
      "  },\n",
      "  \"et_coverage_pct\": {\n",
      "    \"FFD\": \"85.8%\",\n",
      "    \"GD\": \"85.8%\",\n",
      "    \"TRT\": \"85.8%\",\n",
      "    \"GPT\": \"0.0%\"\n",
      "  },\n",
      "  \"eeg_coverage_pct\": {\n",
      "    \"theta1\": \"0.0%\",\n",
      "    \"alpha1\": \"0.0%\",\n",
      "    \"beta1\": \"0.0%\",\n",
      "    \"gamma1\": \"0.0%\"\n",
      "  },\n",
      "  \"files\": {\n",
      "    \"v1_et_mat\": 202,\n",
      "    \"v2_et_mat\": 133,\n",
      "    \"v1_eeg_tabular\": 4,\n",
      "    \"v2_eeg_tabular\": 0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Merge ET + EEG, write outputs, QA, preview\n",
    "import json\n",
    "merged = zuco_loader.merge_et_eeg(df_et, agg_eeg)\n",
    "\n",
    "# Enforce canonical columns order\n",
    "col_order = ['Dataset','Task','Subject','SentenceID','w_pos','token','token_norm','FFD','GD','TRT','GPT','theta1','alpha1','beta1','gamma1']\n",
    "for c in col_order:\n",
    "    if c not in merged.columns:\n",
    "        merged[c] = np.nan\n",
    "merged = merged[col_order]\n",
    "\n",
    "# Save outputs\n",
    "out_csv = PROC / 'zuco_aligned.csv'\n",
    "merged.to_csv(out_csv, index=False)\n",
    "print('Saved:', out_csv)\n",
    "\n",
    "# Build QA\n",
    "qa = zuco_loader.qa_summary(merged, disc, errors={'v1': [], 'v2': []})\n",
    "qa_path = RPTS / 'zuco_loader_qa.json'\n",
    "qa_path.write_text(json.dumps(qa, indent=2))\n",
    "print('QA saved:', qa_path)\n",
    "\n",
    "# Preview\n",
    "print('\\n--- Preview (10 rows) ---')\n",
    "print(merged.head(10))\n",
    "\n",
    "# QA summary\n",
    "print('\\n--- QA Summary ---')\n",
    "print(json.dumps({k: qa[k] for k in ['rows','subjects','by_dataset','by_task','et_coverage_pct','eeg_coverage_pct','files']}, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e930feb",
   "metadata": {},
   "source": [
    "### Fetch missing ZuCo files from OSF (conditional)\n",
    "If required files are missing locally, attempt to download public archives from OSF and extract into `data/raw_public/zuco`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "687c72c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'need_v2_results': False, 'need_v2_et': False}\n",
      "{'v1': {'et_mat': 202, 'eeg_tabular': 4}, 'v2': {'et_mat': 133, 'eeg_tabular': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Conditional OSF fetch for ZuCo v2 results/ET if missing\n",
    "import shutil, subprocess, sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_BASE = RAW\n",
    "V2_DIR = RAW_BASE / 'v2'\n",
    "V1_DIR = RAW_BASE / 'v1'\n",
    "V2_DIR.mkdir(parents=True, exist_ok=True)\n",
    "V1_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Simple checks for presence\n",
    "need_v2_results = True\n",
    "need_v2_et = True\n",
    "for p in V2_DIR.rglob('results*.mat'):\n",
    "    need_v2_results = False; break\n",
    "for p in V2_DIR.rglob('*_corrected_ET.mat'):\n",
    "    need_v2_et = False; break\n",
    "\n",
    "print({'need_v2_results': need_v2_results, 'need_v2_et': need_v2_et})\n",
    "\n",
    "# Try OSF direct links for task2 - TSR (public). If blocked, print instructions.\n",
    "osf_tsr_zip = 'https://osf.io/download/5e6b614f87b00100093a2199/'\n",
    "zip_path = V2_DIR / 'task2-TSR.zip'\n",
    "\n",
    "if need_v2_results or need_v2_et:\n",
    "    try:\n",
    "        # Prefer wget if available\n",
    "        subprocess.run(['wget', '-O', str(zip_path), osf_tsr_zip], check=False)\n",
    "        if zip_path.exists() and zip_path.stat().st_size > 0:\n",
    "            subprocess.run(['unzip', '-o', str(zip_path), '-d', str(V2_DIR)], check=False)\n",
    "            print('Downloaded and extracted TS R archive from OSF.')\n",
    "        else:\n",
    "            print('WARN: Could not download OSF archive automatically. Please download manually and place under data/raw_public/zuco/v2')\n",
    "    except Exception as e:\n",
    "        print('Download error:', e)\n",
    "\n",
    "# Re-run discovery after fetch\n",
    "disc = zuco_loader.discover(RAW)\n",
    "print({k: {'et_mat': len(v.et_mat), 'eeg_tabular': len(v.eeg_tabular)} for k,v in disc.items()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c491bd5d",
   "metadata": {},
   "source": [
    "### Download EEG tabular files from OSF (ZuCo 2.0)\n",
    "Attempt to locate and download EEG word-level tabular files from the public OSF project for ZuCo 2.0 (project id: 2urht)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3bd7f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG present under v2/eeg: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 0 EEG tabular files via osfclient.\n",
      "{'v1': {'et_mat': 202, 'eeg_tabular': 4}, 'v2': {'et_mat': 133, 'eeg_tabular': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Robust OSF crawl to fetch EEG tabular files from ZuCo 2.0\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "save_dir = RAW / 'v2' / 'eeg'\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "have_eeg = any(save_dir.rglob('*.csv')) or any(save_dir.rglob('*.tsv'))\n",
    "print('EEG present under v2/eeg:', have_eeg)\n",
    "\n",
    "if not have_eeg:\n",
    "    try:\n",
    "        osfclient = importlib.import_module('osfclient')\n",
    "        from osfclient import OSF\n",
    "\n",
    "        osf = OSF()\n",
    "        project = osf.project('2urht')  # ZuCo 2.0\n",
    "\n",
    "        def iter_storage_files(storage_or_folder):\n",
    "            # Yield all File objects under a storage or folder recursively\n",
    "            # Storage/Folder in osfclient expose .files() and .folders()\n",
    "            try:\n",
    "                files = list(storage_or_folder.files())\n",
    "            except Exception:\n",
    "                try:\n",
    "                    files = list(storage_or_folder.files)\n",
    "                except Exception:\n",
    "                    files = []\n",
    "            for f in files:\n",
    "                yield f\n",
    "            # Recurse into folders\n",
    "            try:\n",
    "                folders = list(storage_or_folder.folders())\n",
    "            except Exception:\n",
    "                try:\n",
    "                    folders = list(storage_or_folder.folders)\n",
    "                except Exception:\n",
    "                    folders = []\n",
    "            for folder in folders:\n",
    "                yield from iter_storage_files(folder)\n",
    "\n",
    "        # Enumerate storages\n",
    "        storages = []\n",
    "        try:\n",
    "            storages = list(project.storages())\n",
    "        except Exception:\n",
    "            try:\n",
    "                storages = list(project.storages)\n",
    "            except Exception:\n",
    "                storages = []\n",
    "        if not storages:\n",
    "            # Fallback to common slug\n",
    "            try:\n",
    "                storages = [project.storage('osfstorage')]\n",
    "            except Exception:\n",
    "                storages = []\n",
    "\n",
    "        downloaded = 0\n",
    "        for storage in storages:\n",
    "            for file in iter_storage_files(storage):\n",
    "                name = file.name.lower()\n",
    "                if name.endswith('.csv') or name.endswith('.tsv'):\n",
    "                    # Heuristic: only EEG band/word-level exports\n",
    "                    if any(k in name for k in ['eeg', 'theta', 'alpha', 'beta', 'gamma', 'word']):\n",
    "                        out = save_dir / file.name\n",
    "                        try:\n",
    "                            with open(out, 'wb') as f:\n",
    "                                file.write_to(f)\n",
    "                            downloaded += 1\n",
    "                        except Exception:\n",
    "                            continue\n",
    "        print(f'Downloaded {downloaded} EEG tabular files via osfclient.')\n",
    "    except Exception as e:\n",
    "        print('OSF crawl failed. Error:', e)\n",
    "\n",
    "# Re-run discovery to include new EEG files\n",
    "disc = zuco_loader.discover(RAW)\n",
    "print({k: {'et_mat': len(v.et_mat), 'eeg_tabular': len(v.eeg_tabular)} for k,v in disc.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81c7c8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG fallback file found: /home/agourakis82/workspace/pcs-meta-repo/data/processed/zuco_word_level_all_subjects.csv\n",
      "EEG fallback rows: 12446\n",
      "Saved with EEG fallback: /home/agourakis82/workspace/pcs-meta-repo/data/processed/zuco_aligned.csv\n",
      "QA updated: /home/agourakis82/workspace/pcs-meta-repo/notebooks/reports/zuco_loader_qa.json\n"
     ]
    }
   ],
   "source": [
    "# Try EEG fallback from processed file and re-run merge if EEG empty\n",
    "if 'agg_eeg' in globals() and len(agg_eeg) == 0:\n",
    "    fb = RAW.parent.parent / 'processed' / 'zuco_word_level_all_subjects.csv'\n",
    "    if fb.exists():\n",
    "        df_fb = pd.read_csv(fb, low_memory=False)\n",
    "        print('EEG fallback file found:', fb)\n",
    "        # Map to canonical\n",
    "        band_map = {\n",
    "            'ThetaPower': 'theta1', 'AlphaPower': 'alpha1', 'BetaPower': 'beta1', 'GammaPower': 'gamma1'\n",
    "        }\n",
    "        key_map = {\n",
    "            'Dataset': 'Dataset', 'Task': 'Task', 'Subject': 'Subject',\n",
    "            'SentenceID': 'SentenceID', 'Word': 'token', 'token_norm': 'token_norm',\n",
    "        }\n",
    "        avail = [c for c in list(key_map) if c in df_fb.columns]\n",
    "        bands = [c for c in band_map if c in df_fb.columns]\n",
    "        keep = avail + bands\n",
    "        eeg_fb = df_fb[keep].rename(columns={**band_map, **key_map})\n",
    "        # Ensure w_pos is present; if not, set NA\n",
    "        if 'w_pos' not in eeg_fb.columns:\n",
    "            eeg_fb['w_pos'] = pd.NA\n",
    "        # Coerce key types to align with df_et\n",
    "        for c in ['SentenceID','w_pos']:\n",
    "            if c in eeg_fb.columns:\n",
    "                eeg_fb[c] = pd.to_numeric(eeg_fb[c], errors='coerce').astype('Int64')\n",
    "        for c in ['Dataset','Task','Subject','token','token_norm']:\n",
    "            if c in eeg_fb.columns:\n",
    "                eeg_fb[c] = eeg_fb[c].astype(str)\n",
    "        agg_eeg = eeg_fb[['Dataset','Task','Subject','SentenceID','w_pos','token','token_norm','theta1','alpha1','beta1','gamma1']]\n",
    "        print('EEG fallback rows:', len(agg_eeg))\n",
    "        # Re-merge and save\n",
    "        merged = zuco_loader.merge_et_eeg(df_et, agg_eeg)\n",
    "        col_order = ['Dataset','Task','Subject','SentenceID','w_pos','token','token_norm','FFD','GD','TRT','GPT','theta1','alpha1','beta1','gamma1']\n",
    "        for c in col_order:\n",
    "            if c not in merged.columns:\n",
    "                merged[c] = np.nan\n",
    "        merged = merged[col_order]\n",
    "        out_csv = PROC / 'zuco_aligned.csv'\n",
    "        merged.to_csv(out_csv, index=False)\n",
    "        print('Saved with EEG fallback:', out_csv)\n",
    "        # QA\n",
    "        qa = zuco_loader.qa_summary(merged, disc, errors={'v1': [], 'v2': []})\n",
    "        qa_path = RPTS / 'zuco_loader_qa.json'\n",
    "        qa_path.write_text(json.dumps(qa, indent=2))\n",
    "        print('QA updated:', qa_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
