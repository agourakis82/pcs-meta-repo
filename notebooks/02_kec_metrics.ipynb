{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {},
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 02: KEC Metrics Computation\n",
    "Using the SWOW graph from Notebook 01, this notebook computes the *Knowledge Entropy Curvature* (KEC) metrics for each node/word:\n",
    "- **Transition Entropy:** The entropy of outgoing edge weight distribution (uncertainty of associations).\n",
    "- **Local Curvature:** Graph curvature at the node (using Ollivier-Ricci or Forman's method).\n",
    "- **Meso-scale Coherence:** Community-based coherence (e.g., modularity or cluster tightness around the node).\n",
    "\n",
    "Ablation experiments (e.g., edge weight shuffling) and uncertainty estimation (bootstrap confidence intervals) are included.\n",
    "- **Input:** Graph from Notebook 01 (or edge list).\n",
    "- **Output:** Table of KEC metrics per word (saved to `data/processed/kec/metrics_{LANG}.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "source": [
    "# Assume G (graph) is available (from Notebook 01)\n",
    "import math\n",
    "\n",
    "# Compute transition entropy for each node\n",
    "entropy = {}\n",
    "for node in G.nodes():\n",
    "    out_edges = G.out_edges(node, data='weight')\n",
    "    total_w = sum([w for _,_,w in out_edges])\n",
    "    H = 0.0\n",
    "    for _, target, w in out_edges:\n",
    "        p = w / total_w\n",
    "        if p > 0:\n",
    "            H -= p * math.log2(p)\n",
    "    entropy[node] = H\n",
    "print(f\"Calculated entropy for {len(entropy)} nodes.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "source": [
    "# Compute local curvature (using a placeholder or external library)\n",
    "try:\n",
    "    import GraphRicciCurvature\n",
    "    # Using Ollivier-Ricci from an external lib if available\n",
    "    orc = GraphRicciCurvature.OllivierRicci(G, alpha=0.5, verbose=False)\n",
    "    orc.compute_ricci_curvature()\n",
    "    curvature = {edge: data['ricciCurvature'] for edge, data in orc.G.edges.items()}\n",
    "except ImportError:\n",
    "    # Placeholder: approximate curvature by Forman's method as fallback\n",
    "    curvature = {}\n",
    "    for u,v in G.edges():\n",
    "        curvature[(u,v)] = (G.degree(u) + G.degree(v) - 2)  # simplistic Forman proxy\n",
    "print(f\"Computed curvature for {len(curvature)} edges (sample edge curvatures shown below):\")\n",
    "print(list(curvature.items())[:5])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "source": [
    "# Compute coherence: use community detection (e.g., Leiden) to get cluster assignments and measure cluster purity around node\n",
    "import networkx.algorithms.community as nx_comm\n",
    "communities = nx_comm.greedy_modularity_communities(G)\n",
    "node_to_comm = {}\n",
    "for i, comm in enumerate(communities):\n",
    "    for node in comm:\n",
    "        node_to_comm[node] = i\n",
    "coherence = {}\n",
    "for node in G.nodes():\n",
    "    # e.g., coherence = fraction of node's neighbors in same community\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    if neighbors:\n",
    "        same_comm = sum(1 for n in neighbors if node_to_comm.get(n) == node_to_comm.get(node))\n",
    "        coherence[node] = same_comm / len(neighbors)\n",
    "    else:\n",
    "        coherence[node] = None\n",
    "print(f\"Computed coherence for {len(coherence)} nodes.\")"
   ],
   "outputs": []
  }
 ]
}
