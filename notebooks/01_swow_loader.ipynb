{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a3732d",
   "metadata": {},
   "source": [
    "# PCS-HELIO v4.3 â€” Standard environment and helpers\n",
    "This notebook follows the v4.3 conventions (paths, token normalization, and reproducible outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22418569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:08:00] Env ready (v4.3)\n"
     ]
    }
   ],
   "source": [
    "import time, re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def heartbeat(m):\n",
    "    print(f\"[{time.strftime('%H:%M:%S')}] {m}\")\n",
    "\n",
    "def norm_token(s):\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"[\\W_]+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "RAW_DIR = Path('../data/raw_public')\n",
    "PROC_DIR = Path('../data/processed'); PROC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RPT_DIR = Path('reports'); RPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "heartbeat('Env ready (v4.3)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd2702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[env] Python: 3.11.13 | platform: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35\n",
      "[env] numpy: 2.3.2 | pandas: 2.3.2\n",
      "[env] seed: 42 at 2025-09-01 21:08:00\n"
     ]
    }
   ],
   "source": [
    "# Environment & seeds (reproducibility)\n",
    "import sys, platform, time, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "SEED=42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print(f\"[env] Python: {sys.version.split()[0]} | platform: {platform.platform()}\")\n",
    "print(f\"[env] numpy: {np.__version__} | pandas: {pd.__version__}\")\n",
    "print(f\"[env] seed: {SEED} at {time.strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60875f40",
   "metadata": {},
   "source": [
    "# Notebook 01: SWOW Loader\n",
    "Carrega dados do *Small World of Words* usando streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c43389",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run-All cell\"\"\"\n",
    "import random, numpy as np\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6eebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a32eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote ../data/processed/swow/en/swow_en_tidy.csv from zip\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import yaml\n",
    "import zipfile\n",
    "\n",
    "raw_candidates = [\n",
    "    Path(\"../data/raw_public/swow/en/swow_en.csv\"),\n",
    "    Path(\"../data/raw_public/swow/swow_en.csv\"),\n",
    "    Path(\"../data/raw_public/swow_en.csv\"),\n",
    "]\n",
    "zip_candidates = [\n",
    "    Path(\"../data/raw_public/swow/en/swow_en.zip\"),\n",
    "    Path(\"../data/raw_public/swow/swow_en.zip\"),\n",
    "    Path(\"../data/raw_public/swow_en.zip\"),\n",
    "]\n",
    "processed_dir = Path(\"../data/processed/swow/en\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "src_path = next((p for p in raw_candidates if p.exists()), None)\n",
    "if src_path is None:\n",
    "    zip_path = next((p for p in zip_candidates if p.exists()), None)\n",
    "    if zip_path is not None:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "            inner_csv = next((n for n in zf.namelist() if n.endswith('.csv')), None)\n",
    "            if inner_csv is None:\n",
    "                print(f\"No CSV found inside {zip_path}\")\n",
    "            else:\n",
    "                df = pd.read_csv(zf.open(inner_csv), dtype=str)\n",
    "                df.to_csv(processed_dir / \"swow_en_tidy.csv\", index=False)\n",
    "                sha = hashlib.sha256((processed_dir / \"swow_en_tidy.csv\").read_bytes()).hexdigest()\n",
    "                prov = {\"source\": str(zip_path), \"inner\": inner_csv, \"generated\": str(processed_dir / \"swow_en_tidy.csv\"), \"sha256\": sha}\n",
    "                with open(processed_dir / \"provenance.yaml\", \"w\") as fh:\n",
    "                    yaml.safe_dump(prov, fh)\n",
    "                print(f\"Wrote {processed_dir / 'swow_en_tidy.csv'} from zip\")\n",
    "    else:\n",
    "        print(\"SWOW source not found. Expected one of: \")\n",
    "        for p in raw_candidates + zip_candidates:\n",
    "            print(f\" - {p}\")\n",
    "else:\n",
    "    # Stream-read for memory safety\n",
    "    chunks = pd.read_csv(src_path, chunksize=10000, dtype=str)\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "    df.to_csv(processed_dir / \"swow_en_tidy.csv\", index=False)\n",
    "    sha = hashlib.sha256((processed_dir / \"swow_en_tidy.csv\").read_bytes()).hexdigest()\n",
    "    prov = {\"source\": str(src_path), \"generated\": str(processed_dir / \"swow_en_tidy.csv\"), \"sha256\": sha}\n",
    "    with open(processed_dir / \"provenance.yaml\", \"w\") as fh:\n",
    "        yaml.safe_dump(prov, fh)\n",
    "    print(f\"Wrote {processed_dir / 'swow_en_tidy.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
