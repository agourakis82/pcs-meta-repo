{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90443341",
   "metadata": {},
   "source": [
    "# Notebook 01 ‚Äì Data Preprocessing and Network Construction\n",
    "\n",
    "**Author:** Demetrios Agourakis  \n",
    "**ORCID:** [0000-0002-8596-5097](https://orcid.org/0000-0002-8596-5097)  \n",
    "**License:** MIT License  \n",
    "**Code DOI:** [10.5281/zenodo.16752238](https://doi.org/10.5281/zenodo.16752238)  \n",
    "**Data DOI:** [10.17605/OSF.IO/2AQP7](https://doi.org/10.17605/OSF.IO/2AQP7)  \n",
    "**Version:** 1.0 ‚Äì Last updated: 2025-08-07\n",
    "\n",
    "This notebook loads and cleans the SWOW-EN (Small World of Words) dataset.  \n",
    "It prepares the symbolic data for graph construction and subsequent cognitive manifold modelling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99831c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/demetriosagourakis/Library/Mobile Documents/com~apple~CloudDocs/Biologia Fractal/entropic-symbolic-society/NHB_Symbolic_Mainfold\n",
      "Data path: /Users/demetriosagourakis/Library/Mobile Documents/com~apple~CloudDocs/Biologia Fractal/entropic-symbolic-society/NHB_Symbolic_Mainfold/data\n",
      "Results path: /Users/demetriosagourakis/Library/Mobile Documents/com~apple~CloudDocs/Biologia Fractal/entropic-symbolic-society/NHB_Symbolic_Mainfold/results\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "def get_root_path():\n",
    "    current = Path.cwd()\n",
    "    while current != current.parent:\n",
    "        if (current / \"README.md\").exists():\n",
    "            return current\n",
    "        current = current.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "\n",
    "ROOT = get_root_path()\n",
    "DATA = ROOT / \"data\"\n",
    "RESULTS = ROOT / \"results\"\n",
    "DATA.mkdir(exist_ok=True)\n",
    "RESULTS.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {ROOT}\")\n",
    "print(f\"Data path: {DATA}\")\n",
    "print(f\"Results path: {RESULTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "530b12f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (1356362, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>participantID</th>\n",
       "      <th>created_at</th>\n",
       "      <th>age</th>\n",
       "      <th>nativeLanguage</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>section</th>\n",
       "      <th>cue</th>\n",
       "      <th>R1Raw</th>\n",
       "      <th>R2Raw</th>\n",
       "      <th>R3Raw</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "      <th>R3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1500428</td>\n",
       "      <td>130332</td>\n",
       "      <td>2018-01-07 04:29:38</td>\n",
       "      <td>61</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ma</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pepperell</td>\n",
       "      <td>United States</td>\n",
       "      <td>seed</td>\n",
       "      <td>there</td>\n",
       "      <td>position</td>\n",
       "      <td>place</td>\n",
       "      <td>point</td>\n",
       "      <td>position</td>\n",
       "      <td>place</td>\n",
       "      <td>point</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1500426</td>\n",
       "      <td>130332</td>\n",
       "      <td>2018-01-07 04:29:38</td>\n",
       "      <td>61</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ma</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pepperell</td>\n",
       "      <td>United States</td>\n",
       "      <td>seed</td>\n",
       "      <td>true</td>\n",
       "      <td>honest</td>\n",
       "      <td>fact</td>\n",
       "      <td>indisputable</td>\n",
       "      <td>honest</td>\n",
       "      <td>fact</td>\n",
       "      <td>indisputable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1500424</td>\n",
       "      <td>130332</td>\n",
       "      <td>2018-01-07 04:29:38</td>\n",
       "      <td>61</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ma</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pepperell</td>\n",
       "      <td>United States</td>\n",
       "      <td>seed</td>\n",
       "      <td>beat</td>\n",
       "      <td>drum</td>\n",
       "      <td>policeman</td>\n",
       "      <td>beatnik</td>\n",
       "      <td>drum</td>\n",
       "      <td>policeman</td>\n",
       "      <td>beatnik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1500438</td>\n",
       "      <td>130332</td>\n",
       "      <td>2018-01-07 04:29:38</td>\n",
       "      <td>61</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ma</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pepperell</td>\n",
       "      <td>United States</td>\n",
       "      <td>seed</td>\n",
       "      <td>like</td>\n",
       "      <td>affection</td>\n",
       "      <td>simile</td>\n",
       "      <td>compare</td>\n",
       "      <td>affection</td>\n",
       "      <td>simile</td>\n",
       "      <td>compare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1500430</td>\n",
       "      <td>130332</td>\n",
       "      <td>2018-01-07 04:29:38</td>\n",
       "      <td>61</td>\n",
       "      <td>United States</td>\n",
       "      <td>Ma</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Pepperell</td>\n",
       "      <td>United States</td>\n",
       "      <td>seed</td>\n",
       "      <td>telephone</td>\n",
       "      <td>receiver</td>\n",
       "      <td>hamdset</td>\n",
       "      <td>wires</td>\n",
       "      <td>receiver</td>\n",
       "      <td>handset</td>\n",
       "      <td>wires</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id  participantID           created_at  age  \\\n",
       "0           1  1500428         130332  2018-01-07 04:29:38   61   \n",
       "1           2  1500426         130332  2018-01-07 04:29:38   61   \n",
       "2           3  1500424         130332  2018-01-07 04:29:38   61   \n",
       "3           4  1500438         130332  2018-01-07 04:29:38   61   \n",
       "4           5  1500430         130332  2018-01-07 04:29:38   61   \n",
       "\n",
       "  nativeLanguage gender  education       city        country section  \\\n",
       "0  United States     Ma        5.0  Pepperell  United States    seed   \n",
       "1  United States     Ma        5.0  Pepperell  United States    seed   \n",
       "2  United States     Ma        5.0  Pepperell  United States    seed   \n",
       "3  United States     Ma        5.0  Pepperell  United States    seed   \n",
       "4  United States     Ma        5.0  Pepperell  United States    seed   \n",
       "\n",
       "         cue      R1Raw      R2Raw         R3Raw         R1         R2  \\\n",
       "0      there   position      place         point   position      place   \n",
       "1       true     honest       fact  indisputable     honest       fact   \n",
       "2       beat       drum  policeman       beatnik       drum  policeman   \n",
       "3       like  affection     simile       compare  affection     simile   \n",
       "4  telephone   receiver    hamdset         wires   receiver    handset   \n",
       "\n",
       "             R3  \n",
       "0         point  \n",
       "1  indisputable  \n",
       "2       beatnik  \n",
       "3       compare  \n",
       "4         wires  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üîç Dataset filename and expected location\n",
    "filename = \"SWOW-EN.complete.20180827.csv\"\n",
    "file_path = DATA / filename\n",
    "\n",
    "# ‚ùó Manual file placement required\n",
    "if not file_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset not found at {file_path}. Please download it manually from https://osf.io/2AQP7 \"\n",
    "        f\"and place it in the 'data/' directory as '{filename}'.\"\n",
    "    )\n",
    "\n",
    "# üìñ Load dataset\n",
    "df = pd.read_csv(file_path)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea71920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 163 rows with missing or invalid entries.\n",
      "Cleaned data saved to: /Users/demetriosagourakis/Library/Mobile Documents/com~apple~CloudDocs/Biologia Fractal/entropic-symbolic-society/NHB_Symbolic_Mainfold/data/symbolic_cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# ‚úÖ Column mapping based on your dataset\n",
    "df = df.rename(columns={\"cue\": \"stimulus\", \"R1\": \"association\"})\n",
    "\n",
    "initial_shape = df.shape\n",
    "df = df.dropna(subset=[\"stimulus\", \"association\"])\n",
    "df = df[df[\"stimulus\"].apply(lambda x: isinstance(x, str))]\n",
    "df = df[df[\"association\"].apply(lambda x: isinstance(x, str))]\n",
    "print(f\"Dropped {initial_shape[0] - df.shape[0]} rows with missing or invalid entries.\")\n",
    "\n",
    "df[\"stimulus\"] = df[\"stimulus\"].str.strip().str.lower()\n",
    "df[\"association\"] = df[\"association\"].str.strip().str.lower()\n",
    "\n",
    "cleaned_path = DATA / \"symbolic_cleaned_data.csv\"\n",
    "df.to_csv(cleaned_path, index=False)\n",
    "print(f\"Cleaned data saved to: {cleaned_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5a6b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph constructed with 77165 nodes and 542600 edges.\n",
      "Isolated nodes: 0\n",
      "Graph saved to: /Users/demetriosagourakis/Library/Mobile Documents/com~apple~CloudDocs/Biologia Fractal/entropic-symbolic-society/NHB_Symbolic_Mainfold/results/word_network.graphml\n"
     ]
    }
   ],
   "source": [
    "G = nx.DiGraph()\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    stim = row[\"stimulus\"]\n",
    "    assoc = row[\"association\"]\n",
    "    weight = row.get(\"strength\", 1.0)\n",
    "    if not G.has_edge(stim, assoc):\n",
    "        G.add_edge(stim, assoc, weight=weight)\n",
    "    else:\n",
    "        G[stim][assoc][\"weight\"] += weight\n",
    "\n",
    "print(\n",
    "    f\"Graph constructed with {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\"\n",
    ")\n",
    "\n",
    "isolated_nodes = list(nx.isolates(G))\n",
    "print(f\"Isolated nodes: {len(isolated_nodes)}\")\n",
    "\n",
    "graph_path = RESULTS / \"word_network.graphml\"\n",
    "nx.write_graphml(G, graph_path)\n",
    "print(f\"Graph saved to: {graph_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91759de7",
   "metadata": {},
   "source": [
    "## ‚úÖ Notebook Summary\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "- Loaded and verified the SWOW-EN dataset manually from OSF,\n",
    "- Cleaned and standardised symbolic associations into lowercase string pairs,\n",
    "- Constructed a directed graph using NetworkX with weighted edges,\n",
    "- Saved the cleaned data (`symbolic_cleaned_data.csv`) and the resulting graph (`word_network.graphml`) for downstream analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ñ∂Ô∏è Next Step\n",
    "\n",
    "Proceed to **Notebook 02 ‚Äì Network Metrics**, where we will compute centrality and topological properties over the constructed symbolic graph, including:\n",
    "\n",
    "- Degree and strength distributions,\n",
    "- Clustering coefficients,\n",
    "- PageRank and other symbolic influence measures.\n",
    "\n",
    "Ensure that the file `word_network.graphml` is available in the `results/` directory before running the next notebook.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
