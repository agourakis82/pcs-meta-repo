{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "418f38af",
   "metadata": {},
   "source": [
    "# Notebook 04 – Merge Metrics and Embeddings\n",
    "\n",
    "**Author:** Demetrios Agourakis  \n",
    "**ORCID:** [0000-0002-8596-5097](https://orcid.org/0000-0002-8596-5097)  \n",
    "**License:** MIT License  \n",
    "**Code DOI:** [10.5281/zenodo.16752238](https://doi.org/10.5281/zenodo.16752238)  \n",
    "**Data DOI:** [10.17605/OSF.IO/2AQP7](https://doi.org/10.17605/OSF.IO/2AQP7)  \n",
    "**Version:** 1.0 – Last updated: 2025-08-07\n",
    "\n",
    "This notebook merges symbolic network metrics with node embeddings to build a consolidated dataset for clustering and manifold visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2969b79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded metrics: (77165, 11), embeddings: (77165, 129)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_root_path():\n",
    "    current = Path.cwd()\n",
    "    while current != current.parent:\n",
    "        if (current / \"README.md\").exists():\n",
    "            return current\n",
    "        current = current.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "\n",
    "ROOT = get_root_path()\n",
    "DATA = ROOT / \"data\"\n",
    "RESULTS = ROOT / \"results\"\n",
    "DATA.mkdir(exist_ok=True)\n",
    "RESULTS.mkdir(exist_ok=True)\n",
    "\n",
    "metrics_path = DATA / \"symbolic_metrics.csv\"\n",
    "emb_path = DATA / \"symbolic_embeddings.csv\"\n",
    "\n",
    "if not metrics_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing metrics file at: {metrics_path}\")\n",
    "if not emb_path.exists():\n",
    "    raise FileNotFoundError(f\"Missing embeddings file at: {emb_path}\")\n",
    "\n",
    "metrics = pd.read_csv(metrics_path)\n",
    "emb = pd.read_csv(emb_path)\n",
    "\n",
    "print(f\"Loaded metrics: {metrics.shape}, embeddings: {emb.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "badfab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[metrics] dropping 2 rows with empty/invalid node\n",
      "[emb] dropping 2 rows with empty/invalid node\n",
      "nodes in metrics only: 0 | in emb only: 0\n",
      "Merged shape: (77163, 139)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>in_degree</th>\n",
       "      <th>out_degree</th>\n",
       "      <th>total_degree</th>\n",
       "      <th>in_strength</th>\n",
       "      <th>out_strength</th>\n",
       "      <th>total_strength</th>\n",
       "      <th>pagerank</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_118</th>\n",
       "      <th>emb_119</th>\n",
       "      <th>emb_120</th>\n",
       "      <th>emb_121</th>\n",
       "      <th>emb_122</th>\n",
       "      <th>emb_123</th>\n",
       "      <th>emb_124</th>\n",
       "      <th>emb_125</th>\n",
       "      <th>emb_126</th>\n",
       "      <th>emb_127</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>there</td>\n",
       "      <td>84</td>\n",
       "      <td>36</td>\n",
       "      <td>120</td>\n",
       "      <td>238.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.056718</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208297</td>\n",
       "      <td>0.191555</td>\n",
       "      <td>0.054995</td>\n",
       "      <td>-0.328719</td>\n",
       "      <td>-0.102927</td>\n",
       "      <td>-0.063031</td>\n",
       "      <td>-0.139056</td>\n",
       "      <td>-0.034042</td>\n",
       "      <td>-0.285167</td>\n",
       "      <td>0.024825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>position</td>\n",
       "      <td>83</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>158.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.057992</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160407</td>\n",
       "      <td>-0.073331</td>\n",
       "      <td>0.167797</td>\n",
       "      <td>-0.135133</td>\n",
       "      <td>-0.140792</td>\n",
       "      <td>0.005810</td>\n",
       "      <td>-0.108114</td>\n",
       "      <td>0.119782</td>\n",
       "      <td>-0.058968</td>\n",
       "      <td>-0.023226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>true</td>\n",
       "      <td>161</td>\n",
       "      <td>36</td>\n",
       "      <td>197</td>\n",
       "      <td>504.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>619.0</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.059237</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002440</td>\n",
       "      <td>-0.002906</td>\n",
       "      <td>-0.113090</td>\n",
       "      <td>0.016463</td>\n",
       "      <td>-0.006559</td>\n",
       "      <td>-0.034161</td>\n",
       "      <td>-0.044763</td>\n",
       "      <td>0.099563</td>\n",
       "      <td>0.082961</td>\n",
       "      <td>0.089605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honest</td>\n",
       "      <td>108</td>\n",
       "      <td>51</td>\n",
       "      <td>159</td>\n",
       "      <td>453.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.057231</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039796</td>\n",
       "      <td>0.052120</td>\n",
       "      <td>-0.083340</td>\n",
       "      <td>0.070672</td>\n",
       "      <td>0.214605</td>\n",
       "      <td>-0.025857</td>\n",
       "      <td>-0.074921</td>\n",
       "      <td>0.076047</td>\n",
       "      <td>0.180430</td>\n",
       "      <td>0.143099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beat</td>\n",
       "      <td>100</td>\n",
       "      <td>52</td>\n",
       "      <td>152</td>\n",
       "      <td>276.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.057367</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>0.008646</td>\n",
       "      <td>-0.004605</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.011257</td>\n",
       "      <td>-0.023648</td>\n",
       "      <td>-0.036888</td>\n",
       "      <td>-0.022101</td>\n",
       "      <td>-0.003045</td>\n",
       "      <td>-0.005218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       node  in_degree  out_degree  total_degree  in_strength  out_strength  \\\n",
       "0     there         84          36           120        238.0         113.0   \n",
       "1  position         83          62           145        158.0         119.0   \n",
       "2      true        161          36           197        504.0         115.0   \n",
       "3    honest        108          51           159        453.0         112.0   \n",
       "4      beat        100          52           152        276.0         113.0   \n",
       "\n",
       "   total_strength  pagerank  closeness  betweenness  ...   emb_118   emb_119  \\\n",
       "0           351.0  0.000100   0.056718     0.000057  ... -0.208297  0.191555   \n",
       "1           277.0  0.000046   0.057992     0.000128  ... -0.160407 -0.073331   \n",
       "2           619.0  0.000150   0.059237     0.000075  ...  0.002440 -0.002906   \n",
       "3           565.0  0.000084   0.057231     0.000099  ... -0.039796  0.052120   \n",
       "4           389.0  0.000079   0.057367     0.000127  ...  0.002254  0.008646   \n",
       "\n",
       "    emb_120   emb_121   emb_122   emb_123   emb_124   emb_125   emb_126  \\\n",
       "0  0.054995 -0.328719 -0.102927 -0.063031 -0.139056 -0.034042 -0.285167   \n",
       "1  0.167797 -0.135133 -0.140792  0.005810 -0.108114  0.119782 -0.058968   \n",
       "2 -0.113090  0.016463 -0.006559 -0.034161 -0.044763  0.099563  0.082961   \n",
       "3 -0.083340  0.070672  0.214605 -0.025857 -0.074921  0.076047  0.180430   \n",
       "4 -0.004605  0.028234 -0.011257 -0.023648 -0.036888 -0.022101 -0.003045   \n",
       "\n",
       "    emb_127  \n",
       "0  0.024825  \n",
       "1 -0.023226  \n",
       "2  0.089605  \n",
       "3  0.143099  \n",
       "4 -0.005218  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Schema checks and robust key normalization for 'node' ---\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def _ensure_node_column(df, name=\"metrics\"):\n",
    "    # Se veio com índice salvo como 'Unnamed: 0'\n",
    "    if \"node\" not in df.columns:\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df = df.rename(columns={\"Unnamed: 0\": \"node\"})\n",
    "        else:\n",
    "            # fallback: promover o índice a coluna\n",
    "            df = df.reset_index().rename(columns={\"index\": \"node\"})\n",
    "    # Normalizar: string, strip, lower\n",
    "    df[\"node\"] = df[\"node\"].astype(str).str.strip().str.lower()\n",
    "    # Remover entradas vazias/placeholder\n",
    "    bad = df[\"node\"].isin([\"\", \"nan\", \"none\"])\n",
    "    if bad.any():\n",
    "        print(f\"[{name}] dropping {bad.sum()} rows with empty/invalid node\")\n",
    "    df = df[~bad].dropna(subset=[\"node\"])\n",
    "    # Deduplicar\n",
    "    if df[\"node\"].duplicated().any():\n",
    "        dups = df[\"node\"].duplicated().sum()\n",
    "        print(f\"[{name}] dropping {dups} duplicated node entries\")\n",
    "        df = df.drop_duplicates(subset=[\"node\"], keep=\"first\")\n",
    "    return df\n",
    "\n",
    "\n",
    "metrics = _ensure_node_column(metrics, name=\"metrics\")\n",
    "emb = _ensure_node_column(emb, name=\"emb\")\n",
    "\n",
    "# Diagnóstico rápido de interseção\n",
    "left_only = set(metrics[\"node\"]) - set(emb[\"node\"])\n",
    "right_only = set(emb[\"node\"]) - set(metrics[\"node\"])\n",
    "print(f\"nodes in metrics only: {len(left_only)} | in emb only: {len(right_only)}\")\n",
    "\n",
    "# Merge inner por node\n",
    "merged = pd.merge(metrics, emb, on=\"node\", how=\"inner\")\n",
    "print(f\"Merged shape: {merged.shape}\")\n",
    "\n",
    "# Identificar colunas de embedding e sanear NaNs\n",
    "emb_cols = [c for c in merged.columns if c.startswith(\"emb_\")]\n",
    "if len(emb_cols) == 0:\n",
    "    raise RuntimeError(\n",
    "        \"No embedding columns found. Expected columns like 'emb_0', 'emb_1', ...\"\n",
    "    )\n",
    "\n",
    "# Checagens pós-merge (agora devem passar)\n",
    "assert merged[\"node\"].isna().sum() == 0, \"Merged dataset contains NaN in 'node'.\"\n",
    "assert (\n",
    "    merged[emb_cols].isna().sum().sum() == 0\n",
    "), \"Merged dataset contains NaN in embeddings.\"\n",
    "\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146db021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consolidated dataset saved to: /Users/demetriosagourakis/Library/Mobile Documents/com~apple~CloudDocs/Biologia Fractal/entropic-symbolic-society/NHB_Symbolic_Mainfold/data/symbolic_metrics_embeddings.csv\n",
      "Embedding column list saved to: /Users/demetriosagourakis/Library/Mobile Documents/com~apple~CloudDocs/Biologia Fractal/entropic-symbolic-society/NHB_Symbolic_Mainfold/data/embedding_columns.txt\n"
     ]
    }
   ],
   "source": [
    "out_csv = DATA / \"symbolic_metrics_embeddings.csv\"\n",
    "merged.to_csv(out_csv, index=False)\n",
    "print(f\"Consolidated dataset saved to: {out_csv}\")\n",
    "\n",
    "# Save embedding column names as a sidecar file (useful for downstream notebooks)\n",
    "emb_cols_path = DATA / \"embedding_columns.txt\"\n",
    "with open(emb_cols_path, \"w\") as f:\n",
    "    for c in [c for c in merged.columns if c.startswith(\"emb_\")]:\n",
    "        f.write(f\"{c}\\n\")\n",
    "print(f\"Embedding column list saved to: {emb_cols_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691825cf",
   "metadata": {},
   "source": [
    "## ✅ Notebook Summary\n",
    "\n",
    "We merged node-level symbolic network metrics with vector embeddings to produce a unified dataset:\n",
    "- Input: `data/symbolic_metrics.csv` and `data/symbolic_embeddings.csv`\n",
    "- Output: `data/symbolic_metrics_embeddings.csv`\n",
    "- A helper file `data/embedding_columns.txt` lists embedding columns (e.g., `emb_0 ... emb_127`)\n",
    "\n",
    "---\n",
    "\n",
    "## ▶️ Next Step\n",
    "\n",
    "Proceed to **Notebook 05 – Clustering Analysis**, where we will select an optimal number of clusters and evaluate cluster validity (e.g., silhouette analysis) on the merged feature space.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
