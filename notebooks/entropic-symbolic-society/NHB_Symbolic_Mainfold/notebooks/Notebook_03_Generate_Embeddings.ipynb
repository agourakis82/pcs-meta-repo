{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680e4547",
   "metadata": {},
   "source": [
    "# Notebook 03 – Generate Embeddings\n",
    "\n",
    "**Author:** Demetrios Agourakis  \n",
    "**ORCID:** [0000-0002-8596-5097](https://orcid.org/0000-0002-8596-5097)  \n",
    "**License:** MIT License  \n",
    "**Code DOI:** [10.5281/zenodo.16752238](https://doi.org/10.5281/zenodo.16752238)  \n",
    "**Data DOI:** [10.17605/OSF.IO/2AQP7](https://doi.org/10.17605/OSF.IO/2AQP7)  \n",
    "**Version:** 1.0 – Last updated: 2025-08-07\n",
    "\n",
    "This notebook computes vector embeddings for each node in the symbolic graph.  \n",
    "Primary method: **Truncated SVD** on the sparse adjacency (robust, dependency-light).  \n",
    "Optional method (if installed): **node2vec** random-walk embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e25f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded: 77165 nodes, 542600 edges\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "\n",
    "def get_root_path():\n",
    "    current = Path.cwd()\n",
    "    while current != current.parent:\n",
    "        if (current / \"README.md\").exists():\n",
    "            return current\n",
    "        current = current.parent\n",
    "    return Path.cwd()\n",
    "\n",
    "\n",
    "ROOT = get_root_path()\n",
    "DATA = ROOT / \"data\"\n",
    "RESULTS = ROOT / \"results\"\n",
    "DATA.mkdir(exist_ok=True)\n",
    "RESULTS.mkdir(exist_ok=True)\n",
    "\n",
    "graph_path = RESULTS / \"word_network.graphml\"\n",
    "if not graph_path.exists():\n",
    "    raise FileNotFoundError(f\"Graph not found at: {graph_path}\")\n",
    "G = nx.read_graphml(graph_path)\n",
    "print(f\"Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "\n",
    "# Parameters\n",
    "EMBED_DIM = 128  # embedding dimensionality\n",
    "METHOD = \"svd\"  # 'svd' (default) or 'node2vec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4819fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       node     emb_0     emb_1     emb_2     emb_3     emb_4     emb_5  \\\n",
      "0     there  0.028328  0.001385 -0.006058  0.003627  0.006712  0.006427   \n",
      "1  position  0.169598  0.006578 -0.016645  0.002050  0.006176 -0.001688   \n",
      "2      true  0.038515  0.007363  0.000378 -0.002922  0.007982  0.011319   \n",
      "3    honest  0.291430 -0.007006 -0.015285 -0.018848  0.018152 -0.005375   \n",
      "4      beat  0.044751  0.060966 -0.005857  0.011766 -0.003583 -0.004401   \n",
      "\n",
      "      emb_6     emb_7     emb_8  ...   emb_118   emb_119   emb_120   emb_121  \\\n",
      "0  0.003370  0.005006  0.009515  ... -0.208297  0.191555  0.054995 -0.328719   \n",
      "1 -0.000508  0.007833  0.032174  ... -0.160407 -0.073331  0.167797 -0.135133   \n",
      "2 -0.002269  0.009037  0.008605  ...  0.002440 -0.002906 -0.113090  0.016463   \n",
      "3 -0.003696  0.000438  0.003351  ... -0.039796  0.052120 -0.083340  0.070672   \n",
      "4 -0.018799  0.203360  0.935140  ...  0.002254  0.008646 -0.004605  0.028234   \n",
      "\n",
      "    emb_122   emb_123   emb_124   emb_125   emb_126   emb_127  \n",
      "0 -0.102927 -0.063031 -0.139056 -0.034042 -0.285167  0.024825  \n",
      "1 -0.140792  0.005810 -0.108114  0.119782 -0.058968 -0.023226  \n",
      "2 -0.006559 -0.034161 -0.044763  0.099563  0.082961  0.089605  \n",
      "3  0.214605 -0.025857 -0.074921  0.076047  0.180430  0.143099  \n",
      "4 -0.011257 -0.023648 -0.036888 -0.022101 -0.003045 -0.005218  \n",
      "\n",
      "[5 rows x 129 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "nodes = list(G.nodes())\n",
    "node_index = {n: i for i, n in enumerate(nodes)}\n",
    "\n",
    "A = nx.to_scipy_sparse_array(\n",
    "    G, nodelist=nodes, weight=\"weight\", dtype=np.float64, format=\"csr\"\n",
    ")\n",
    "\n",
    "row_sums = np.array(A.sum(axis=1)).ravel()\n",
    "row_sums[row_sums == 0.0] = 1.0\n",
    "D_inv = csr_matrix(\n",
    "    (1.0 / row_sums, (np.arange(A.shape[0]), np.arange(A.shape[0]))), shape=A.shape\n",
    ")\n",
    "A_norm = D_inv @ A\n",
    "\n",
    "svd = TruncatedSVD(n_components=EMBED_DIM, random_state=SEED)\n",
    "X = svd.fit_transform(A_norm)\n",
    "X = normalize(X, norm=\"l2\", axis=1)\n",
    "\n",
    "emb_cols = [f\"emb_{i}\" for i in range(X.shape[1])]\n",
    "emb_df = (\n",
    "    pd.DataFrame(X, index=nodes, columns=emb_cols)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"index\": \"node\"})\n",
    ")\n",
    "print(emb_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5dd65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional node2vec method\n",
    "try:\n",
    "    if METHOD.lower() == \"node2vec\":\n",
    "        from node2vec import Node2Vec\n",
    "\n",
    "        node2vec = Node2Vec(\n",
    "            G,\n",
    "            dimensions=EMBED_DIM,\n",
    "            walk_length=40,\n",
    "            num_walks=10,\n",
    "            p=1,\n",
    "            q=1,\n",
    "            workers=1,\n",
    "            seed=SEED,\n",
    "            weight_key=\"weight\",\n",
    "            quiet=True,\n",
    "        )\n",
    "        model = node2vec.fit(window=10, min_count=1, batch_words=64)\n",
    "        nodes = list(G.nodes())\n",
    "        import numpy as np\n",
    "\n",
    "        X_nv = np.vstack(\n",
    "            [\n",
    "                model.wv[str(n)] if str(n) in model.wv else np.zeros(EMBED_DIM)\n",
    "                for n in nodes\n",
    "            ]\n",
    "        )\n",
    "        from sklearn.preprocessing import normalize\n",
    "\n",
    "        X_nv = normalize(X_nv, norm=\"l2\", axis=1)\n",
    "        emb_cols = [f\"emb_{i}\" for i in range(X_nv.shape[1])]\n",
    "        emb_df = (\n",
    "            pd.DataFrame(X_nv, index=nodes, columns=emb_cols)\n",
    "            .reset_index()\n",
    "            .rename(columns={\"index\": \"node\"})\n",
    "        )\n",
    "        print(\"node2vec embeddings computed.\")\n",
    "except Exception as e:\n",
    "    print(f\"node2vec not used: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84c1c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to: /Users/demetriosagourakis/Library/Mobile Documents/com~apple~CloudDocs/Biologia Fractal/entropic-symbolic-society/NHB_Symbolic_Mainfold/data/symbolic_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "emb_path = DATA / \"symbolic_embeddings.csv\"\n",
    "emb_df.to_csv(emb_path, index=False)\n",
    "print(f\"Embeddings saved to: {emb_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a00da09",
   "metadata": {},
   "source": [
    "## ✅ Notebook Summary\n",
    "\n",
    "In this notebook, we generated node embeddings for the symbolic network using a robust SVD-based method (and optionally node2vec if installed).  \n",
    "Results were saved to `data/symbolic_embeddings.csv` with columns `node, emb_0, ..., emb_{d-1}`.\n",
    "\n",
    "---\n",
    "\n",
    "## ▶️ Next Step\n",
    "\n",
    "Proceed to **Notebook 04 – Merge Metrics and Embeddings**, to join `symbolic_metrics.csv` and `symbolic_embeddings.csv` into a consolidated table for clustering and manifold visualization.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
