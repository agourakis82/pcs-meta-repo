{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240fb2e8",
   "metadata": {},
   "source": [
    "# PCS‑HELIO v4.3 — 02 · KEC Metrics\n",
    "Compute Knowledge Entropy Curvature (KEC) metrics from SWOW; write standardized outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "helio-preflight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:41.347688Z",
     "iopub.status.busy": "2025-09-02T12:25:41.347171Z",
     "iopub.status.idle": "2025-09-02T12:25:41.777966Z",
     "shell.execute_reply": "2025-09-02T12:25:41.777295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STYLE] _style.css not found; proceeding.\n",
      "[Preflight] Python: 3.12.11 | Platform: Linux-5.15.167.4-microsoft-standard-WSL2-x86_64-with-glibc2.35\n",
      "[Preflight] pandas: 2.3.2 | numpy: 1.26.4\n",
      "[Preflight] Folders ready.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "**Notebook Contract (PCS‑HELIO v4.3)**\n",
       "- IMRaD sections (Intro/Methods/Results/Discussion).\n",
       "- RUN_MODE ∈ {'sample','full'}; sample must run fast and never crash.\n",
       "- Required outputs saved under data/processed/** and reports/**.\n",
       "- QA cell with asserts (columns present, row counts, coverage).\n",
       "- Seeds fixed; no absolute paths; public data only.\n",
       "</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys, json\n",
    "# Ensure repo root on sys.path so 'notebooks._fragments' resolves regardless of CWD\n",
    "ROOT = Path.cwd()\n",
    "if (ROOT/'notebooks'/'_fragments.py').exists():\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "elif (ROOT.parent/'notebooks'/'_fragments.py').exists():\n",
    "    sys.path.insert(0, str(ROOT.parent))\n",
    "try:\n",
    "    from notebooks._fragments import apply_style, preflight_checks, print_contract\n",
    "except Exception as e:\n",
    "    print('[preflight] Failed importing notebooks._fragments:', e)\n",
    "    def apply_style(): pass\n",
    "    def preflight_checks(): pass\n",
    "    def print_contract(): pass\n",
    "apply_style(); preflight_checks(); print_contract()\n",
    "RUN_MODE = os.environ.get('RUN_MODE','sample')\n",
    "BASE=Path('.') ; DATA=BASE/'data' ; PROC=DATA/'processed' ; RPTS=BASE/'reports'\n",
    "(PROC/'kec').mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd290265",
   "metadata": {},
   "source": [
    "# Notebook 02: KEC Metrics Computation\n",
    "Using the SWOW graph from Notebook 01, this notebook computes the *Knowledge Entropy Curvature* (KEC) metrics for each node/word:\n",
    "- **Transition Entropy:** The entropy of outgoing edge weight distribution (uncertainty of associations).\n",
    "- **Local Curvature:** Graph curvature at the node (using Ollivier-Ricci or Forman's method).\n",
    "- **Meso-scale Coherence:** Community-based coherence (e.g., modularity or cluster tightness around the node).\n",
    "\n",
    "Ablation experiments (e.g., edge weight shuffling) and uncertainty estimation (bootstrap confidence intervals) are included.\n",
    "- **Input:** Graph from Notebook 01 (or edge list).\n",
    "- **Output:** Table of KEC metrics per word (saved to `data/processed/kec/metrics_{LANG}.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53d7a6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:41.780376Z",
     "iopub.status.busy": "2025-09-02T12:25:41.780085Z",
     "iopub.status.idle": "2025-09-02T12:25:41.884910Z",
     "shell.execute_reply": "2025-09-02T12:25:41.884076Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph loaded: 7 nodes, 5 edges.\n",
      "Undirected graph created: 7 nodes, 5 edges.\n"
     ]
    }
   ],
   "source": [
    "# Load the SWOW graph from Notebook 01\n",
    "import pickle\n",
    "LANG = 'en'\n",
    "graph_file = str((PROC / f'swow_graph_{LANG}.pkl'))\n",
    "with open(graph_file, 'rb') as f:\n",
    "    G = pickle.load(f)\n",
    "print(f\"Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges.\")\n",
    "# Create undirected version for community detection\n",
    "G_ud = G.to_undirected()\n",
    "# In sample mode, restrict to a subgraph of top-degree nodes for speed\n",
    "if 'RUN_MODE' in globals() and RUN_MODE == 'sample' and G.number_of_nodes() > 1000:\n",
    "    deg = sorted(G.degree, key=lambda x: x[1], reverse=True)\n",
    "    keep = [n for n,_ in deg[:2000]]\n",
    "    G = G.subgraph(keep).copy()\n",
    "    G_ud = G_ud.subgraph(keep).copy()\n",
    "print(f\"Undirected graph created: {G_ud.number_of_nodes()} nodes, {G_ud.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967de366",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:41.886974Z",
     "iopub.status.busy": "2025-09-02T12:25:41.886672Z",
     "iopub.status.idle": "2025-09-02T12:25:41.904854Z",
     "shell.execute_reply": "2025-09-02T12:25:41.903996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated entropy for 7 nodes.\n",
      "Saved entropy to data/processed/kec/entropy.parquet\n"
     ]
    }
   ],
   "source": [
    "# Assume G (graph) is available (from Notebook 01)\n",
    "import math\n",
    "\n",
    "# Compute transition entropy for each node\n",
    "entropy = {}\n",
    "for node in G.nodes():\n",
    "    out_edges = G.out_edges(node, data='weight')\n",
    "    total_w = sum([w for _,_,w in out_edges])\n",
    "    H = 0.0\n",
    "    for _, target, w in out_edges:\n",
    "        p = w / total_w\n",
    "        if p > 0:\n",
    "            H -= p * math.log2(p)\n",
    "    entropy[node] = H\n",
    "print(f\"Calculated entropy for {len(entropy)} nodes.\")\n",
    "\n",
    "# Save entropy as parquet\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "OUTDIR = PROC/\"kec\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "ent_df = pd.DataFrame(list(entropy.items()), columns=['node', 'entropy'])\n",
    "ent_df.to_parquet(OUTDIR/\"entropy.parquet\")\n",
    "print(f\"Saved entropy to {OUTDIR/'entropy.parquet'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8474405e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:41.907148Z",
     "iopub.status.busy": "2025-09-02T12:25:41.906920Z",
     "iopub.status.idle": "2025-09-02T12:25:43.273454Z",
     "shell.execute_reply": "2025-09-02T12:25:43.272464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "\t\t\t<script type=\"text/javascript\">\n",
       "\t\t\t<!--\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_script');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('script');\n",
       "\t\t\t\telement.type = 'text/javascript';\n",
       "\t\t\t\telement.innerHTML = 'function NetworKit_pageEmbed(id) { var i, j; var elements; elements = document.getElementById(id).getElementsByClassName(\"Plot\"); for (i=0; i<elements.length; i++) { elements[i].id = id + \"_Plot_\" + i; var data = elements[i].getAttribute(\"data-image\").split(\"|\"); elements[i].removeAttribute(\"data-image\"); var content = \"<div class=\\\\\"Image\\\\\" id=\\\\\"\" + elements[i].id + \"_Image\\\\\" />\"; elements[i].innerHTML = content; elements[i].setAttribute(\"data-image-index\", 0); elements[i].setAttribute(\"data-image-length\", data.length); for (j=0; j<data.length; j++) { elements[i].setAttribute(\"data-image-\" + j, data[j]); } NetworKit_plotUpdate(elements[i]); elements[i].onclick = function (e) { NetworKit_overlayShow((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"HeatCell\"); for (i=0; i<elements.length; i++) { var data = parseFloat(elements[i].getAttribute(\"data-heat\")); var color = \"#00FF00\"; if (data <= 1 && data > 0) { color = \"hsla(0, 100%, 75%, \" + (data) + \")\"; } else if (data <= 0 && data >= -1) { color = \"hsla(240, 100%, 75%, \" + (-data) + \")\"; } elements[i].style.backgroundColor = color; } elements = document.getElementById(id).getElementsByClassName(\"Details\"); for (i=0; i<elements.length; i++) { elements[i].setAttribute(\"data-title\", \"-\"); NetworKit_toggleDetails(elements[i]); elements[i].onclick = function (e) { NetworKit_toggleDetails((e.target) ? e.target : e.srcElement); } } elements = document.getElementById(id).getElementsByClassName(\"MathValue\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"nan\") { elements[i].parentNode.innerHTML = \"\" } } elements = document.getElementById(id).getElementsByClassName(\"SubCategory\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } elements = document.getElementById(id).getElementsByClassName(\"Category\"); for (i=elements.length-1; i>=0; i--) { value = elements[i].innerHTML.trim(); if (value === \"\") { elements[i].parentNode.removeChild(elements[i]) } } var isFirefox = false; try { isFirefox = typeof InstallTrigger !== \"undefined\"; } catch (e) {} if (!isFirefox) { alert(\"Currently the function\\'s output is only fully supported by Firefox.\"); } } function NetworKit_plotUpdate(source) { var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(source.id + \"_Image\"); image.style.backgroundImage = \"url(\" + data + \")\"; } function NetworKit_showElement(id, show) { var element = document.getElementById(id); element.style.display = (show) ? \"block\" : \"none\"; } function NetworKit_overlayShow(source) { NetworKit_overlayUpdate(source); NetworKit_showElement(\"NetworKit_Overlay\", true); } function NetworKit_overlayUpdate(source) { document.getElementById(\"NetworKit_Overlay_Title\").innerHTML = source.title; var index = source.getAttribute(\"data-image-index\"); var data = source.getAttribute(\"data-image-\" + index); var image = document.getElementById(\"NetworKit_Overlay_Image\"); image.setAttribute(\"data-id\", source.id); image.style.backgroundImage = \"url(\" + data + \")\"; var link = document.getElementById(\"NetworKit_Overlay_Toolbar_Bottom_Save\"); link.href = data; link.download = source.title + \".svg\"; } function NetworKit_overlayImageShift(delta) { var image = document.getElementById(\"NetworKit_Overlay_Image\"); var source = document.getElementById(image.getAttribute(\"data-id\")); var index = parseInt(source.getAttribute(\"data-image-index\")); var length = parseInt(source.getAttribute(\"data-image-length\")); var index = (index+delta) % length; if (index < 0) { index = length + index; } source.setAttribute(\"data-image-index\", index); NetworKit_overlayUpdate(source); } function NetworKit_toggleDetails(source) { var childs = source.children; var show = false; if (source.getAttribute(\"data-title\") == \"-\") { source.setAttribute(\"data-title\", \"+\"); show = false; } else { source.setAttribute(\"data-title\", \"-\"); show = true; } for (i=0; i<childs.length; i++) { if (show) { childs[i].style.display = \"block\"; } else { childs[i].style.display = \"none\"; } } }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_script');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_style');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('style');\n",
       "\t\t\t\telement.type = 'text/css';\n",
       "\t\t\t\telement.innerHTML = '.NetworKit_Page { font-family: Arial, Helvetica, sans-serif; font-size: 14px; } .NetworKit_Page .Value:before { font-family: Arial, Helvetica, sans-serif; font-size: 1.05em; content: attr(data-title) \":\"; margin-left: -2.5em; padding-right: 0.5em; } .NetworKit_Page .Details .Value:before { display: block; } .NetworKit_Page .Value { font-family: monospace; white-space: pre; padding-left: 2.5em; white-space: -moz-pre-wrap !important; white-space: -pre-wrap; white-space: -o-pre-wrap; white-space: pre-wrap; word-wrap: break-word; tab-size: 4; -moz-tab-size: 4; } .NetworKit_Page .Category { clear: both; padding-left: 1em; margin-bottom: 1.5em; } .NetworKit_Page .Category:before { content: attr(data-title); font-size: 1.75em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory { margin-bottom: 1.5em; padding-left: 1em; } .NetworKit_Page .SubCategory:before { font-size: 1.6em; display: block; margin-left: -0.8em; margin-bottom: 0.5em; } .NetworKit_Page .SubCategory[data-title]:before { content: attr(data-title); } .NetworKit_Page .Block { display: block; } .NetworKit_Page .Block:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .Block .Thumbnail_Overview, .NetworKit_Page .Block .Thumbnail_ScatterPlot { width: 260px; float: left; } .NetworKit_Page .Block .Thumbnail_Overview img, .NetworKit_Page .Block .Thumbnail_ScatterPlot img { width: 260px; } .NetworKit_Page .Block .Thumbnail_Overview:before, .NetworKit_Page .Block .Thumbnail_ScatterPlot:before { display: block; text-align: center; font-weight: bold; } .NetworKit_Page .Block .Thumbnail_Overview:before { content: attr(data-title); } .NetworKit_Page .HeatCell { font-family: \"Courier New\", Courier, monospace; cursor: pointer; } .NetworKit_Page .HeatCell, .NetworKit_Page .HeatCellName { display: inline; padding: 0.1em; margin-right: 2px; background-color: #FFFFFF } .NetworKit_Page .HeatCellName { margin-left: 0.25em; } .NetworKit_Page .HeatCell:before { content: attr(data-heat); display: inline-block; color: #000000; width: 4em; text-align: center; } .NetworKit_Page .Measure { clear: both; } .NetworKit_Page .Measure .Details { cursor: pointer; } .NetworKit_Page .Measure .Details:before { content: \"[\" attr(data-title) \"]\"; display: block; } .NetworKit_Page .Measure .Details .Value { border-left: 1px dotted black; margin-left: 0.4em; padding-left: 3.5em; pointer-events: none; } .NetworKit_Page .Measure .Details .Spacer:before { content: \".\"; opacity: 0.0; pointer-events: none; } .NetworKit_Page .Measure .Plot { width: 440px; height: 440px; cursor: pointer; float: left; margin-left: -0.9em; margin-right: 20px; } .NetworKit_Page .Measure .Plot .Image { background-repeat: no-repeat; background-position: center center; background-size: contain; height: 100%; pointer-events: none; } .NetworKit_Page .Measure .Stat { width: 500px; float: left; } .NetworKit_Page .Measure .Stat .Group { padding-left: 1.25em; margin-bottom: 0.75em; } .NetworKit_Page .Measure .Stat .Group .Title { font-size: 1.1em; display: block; margin-bottom: 0.3em; margin-left: -0.75em; border-right-style: dotted; border-right-width: 1px; border-bottom-style: dotted; border-bottom-width: 1px; background-color: #D0D0D0; padding-left: 0.2em; } .NetworKit_Page .Measure .Stat .Group .List { -webkit-column-count: 3; -moz-column-count: 3; column-count: 3; } .NetworKit_Page .Measure .Stat .Group .List .Entry { position: relative; line-height: 1.75em; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:before { position: absolute; left: 0; top: -40px; background-color: #808080; color: #ffffff; height: 30px; line-height: 30px; border-radius: 5px; padding: 0 15px; content: attr(data-tooltip); white-space: nowrap; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:after { position: absolute; left: 15px; top: -10px; border-top: 7px solid #808080; border-left: 7px solid transparent; border-right: 7px solid transparent; content: \"\"; display: none; } .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:after, .NetworKit_Page .Measure .Stat .Group .List .Entry[data-tooltip]:hover:before { display: block; } .NetworKit_Page .Measure .Stat .Group .List .Entry .MathValue { font-family: \"Courier New\", Courier, monospace; } .NetworKit_Page .Measure:after { content: \".\"; visibility: hidden; display: block; height: 0; clear: both; } .NetworKit_Page .PartitionPie { clear: both; } .NetworKit_Page .PartitionPie img { width: 600px; } #NetworKit_Overlay { left: 0px; top: 0px; display: none; position: absolute; width: 100%; height: 100%; background-color: rgba(0,0,0,0.6); z-index: 1000; } #NetworKit_Overlay_Title { position: absolute; color: white; transform: rotate(-90deg); width: 32em; height: 32em; padding-right: 0.5em; padding-top: 0.5em; text-align: right; font-size: 40px; } #NetworKit_Overlay .button { background: white; cursor: pointer; } #NetworKit_Overlay .button:before { size: 13px; display: inline-block; text-align: center; margin-top: 0.5em; margin-bottom: 0.5em; width: 1.5em; height: 1.5em; } #NetworKit_Overlay .icon-close:before { content: \"X\"; } #NetworKit_Overlay .icon-previous:before { content: \"P\"; } #NetworKit_Overlay .icon-next:before { content: \"N\"; } #NetworKit_Overlay .icon-save:before { content: \"S\"; } #NetworKit_Overlay_Toolbar_Top, #NetworKit_Overlay_Toolbar_Bottom { position: absolute; width: 40px; right: 13px; text-align: right; z-index: 1100; } #NetworKit_Overlay_Toolbar_Top { top: 0.5em; } #NetworKit_Overlay_Toolbar_Bottom { Bottom: 0.5em; } #NetworKit_Overlay_ImageContainer { position: absolute; top: 5%; left: 5%; height: 90%; width: 90%; background-repeat: no-repeat; background-position: center center; background-size: contain; } #NetworKit_Overlay_Image { height: 100%; width: 100%; background-repeat: no-repeat; background-position: center center; background-size: contain; }';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_style');\n",
       "\t\t\t\tdocument.head.appendChild(element);\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t\t\n",
       "\t\t\t{\n",
       "\t\t\t\tvar element = document.getElementById('NetworKit_Overlay');\n",
       "\t\t\t\tif (element) {\n",
       "\t\t\t\t\telement.parentNode.removeChild(element);\n",
       "\t\t\t\t}\n",
       "\t\t\t\telement = document.createElement('div');\n",
       "\t\t\t\telement.innerHTML = '<div id=\"NetworKit_Overlay_Toolbar_Top\"><div class=\"button icon-close\" id=\"NetworKit_Overlay_Close\" /></div><div id=\"NetworKit_Overlay_Title\" /> <div id=\"NetworKit_Overlay_ImageContainer\"> <div id=\"NetworKit_Overlay_Image\" /> </div> <div id=\"NetworKit_Overlay_Toolbar_Bottom\"> <div class=\"button icon-previous\" onclick=\"NetworKit_overlayImageShift(-1)\" /> <div class=\"button icon-next\" onclick=\"NetworKit_overlayImageShift(1)\" /> <a id=\"NetworKit_Overlay_Toolbar_Bottom_Save\"><div class=\"button icon-save\" /></a> </div>';\n",
       "\t\t\t\telement.setAttribute('id', 'NetworKit_Overlay');\n",
       "\t\t\t\tdocument.body.appendChild(element);\n",
       "\t\t\t\tdocument.getElementById('NetworKit_Overlay_Close').onclick = function (e) {\n",
       "\t\t\t\t\tdocument.getElementById('NetworKit_Overlay').style.display = 'none';\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\n",
       "\t\t\t-->\n",
       "\t\t\t</script>\n",
       "\t\t"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect verbose level, option:[\"INFO\",\"DEBUG\",\"ERROR\"], use \"ERROR instead.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agourakis82/miniforge3/lib/python3.12/site-packages/ot/lp/__init__.py:634: UserWarning: Input histogram consists of integer. The transport plan will be casted accordingly, possibly resulting in a loss of precision. If this behaviour is unwanted, please make sure your input histogram consists of floating point elements.\n",
      "  return f(b)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agourakis82/miniforge3/lib/python3.12/site-packages/ot/lp/__init__.py:634: UserWarning: Input histogram consists of integer. The transport plan will be casted accordingly, possibly resulting in a loss of precision. If this behaviour is unwanted, please make sure your input histogram consists of floating point elements.\n",
      "  return f(b)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agourakis82/miniforge3/lib/python3.12/site-packages/ot/lp/__init__.py:634: UserWarning: Input histogram consists of integer. The transport plan will be casted accordingly, possibly resulting in a loss of precision. If this behaviour is unwanted, please make sure your input histogram consists of floating point elements.\n",
      "  return f(b)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agourakis82/miniforge3/lib/python3.12/site-packages/ot/lp/__init__.py:634: UserWarning: Input histogram consists of integer. The transport plan will be casted accordingly, possibly resulting in a loss of precision. If this behaviour is unwanted, please make sure your input histogram consists of floating point elements.\n",
      "  return f(b)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agourakis82/miniforge3/lib/python3.12/site-packages/ot/lp/__init__.py:634: UserWarning: Input histogram consists of integer. The transport plan will be casted accordingly, possibly resulting in a loss of precision. If this behaviour is unwanted, please make sure your input histogram consists of floating point elements.\n",
      "  return f(b)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed curvature for 5 edges (sample edge curvatures shown below):\n",
      "[(('cat', 'meow'), 0.0), (('cat', 'pet'), 0.0), (('dog', 'bark'), 0.0), (('dog', 'pet'), 0.0), (('music', 'sound'), 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# Compute local curvature (try Ollivier-Ricci; fallback to simple Forman-like proxy)\n",
    "curvature = {}\n",
    "try:\n",
    "    try:\n",
    "        from GraphRicciCurvature.OllivierRicci import OllivierRicci as _OR\n",
    "    except Exception:\n",
    "        try:\n",
    "            from GraphRicciCurvature import OllivierRicci as _OR\n",
    "        except Exception:\n",
    "            _OR = None\n",
    "    if _OR is not None:\n",
    "        try:\n",
    "            orc = _OR(G, alpha=0.5, verbose=False)\n",
    "            orc.compute_ricci_curvature()\n",
    "            curvature = {edge: data.get('ricciCurvature', data.get('ricciCurvature', 0.0)) for edge, data in orc.G.edges.items()}\n",
    "        except Exception as e:\n",
    "            print('[warn] OllivierRicci failed, using proxy:', e)\n",
    "            curvature = {}\n",
    "    if not curvature:\n",
    "        # Fallback: approximate curvature by simple degree-based proxy (Forman-like)\n",
    "        for u,v in G.edges():\n",
    "            curvature[(u,v)] = float(G.degree(u) + G.degree(v) - 2)\n",
    "except Exception as e:\n",
    "    print('[warn] Curvature computation failed, using proxy:', e)\n",
    "    curvature = {}\n",
    "    for u,v in G.edges():\n",
    "        curvature[(u,v)] = float(G.degree(u) + G.degree(v) - 2)\n",
    "print(f\"Computed curvature for {len(curvature)} edges (sample edge curvatures shown below):\")\n",
    "print(list(curvature.items())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e23cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:43.276063Z",
     "iopub.status.busy": "2025-09-02T12:25:43.275452Z",
     "iopub.status.idle": "2025-09-02T12:25:43.291923Z",
     "shell.execute_reply": "2025-09-02T12:25:43.291137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leidenalg not available, using NetworkX greedy_modularity_communities (may be slow)\n",
      "Computed coherence for 7 nodes.\n",
      "Saved communities to data/processed/kec/communities_leiden.parquet\n",
      "Saved coherence to data/processed/kec/coherence.parquet\n"
     ]
    }
   ],
   "source": [
    "# Compute coherence: use community detection (e.g., Leiden) to get cluster assignments and measure cluster purity around node\n",
    "# Note: greedy_modularity_communities can be slow on large graphs, consider using leidenalg if available\n",
    "try:\n",
    "    import leidenalg\n",
    "    import igraph as ig\n",
    "    # Convert NetworkX graph to igraph for faster community detection\n",
    "    nx_g = G_ud  # Use undirected graph\n",
    "    ig_g = ig.Graph.from_networkx(nx_g)\n",
    "    partition = leidenalg.find_partition(ig_g, leidenalg.ModularityVertexPartition)\n",
    "    communities = [set(ig_g.vs[comm]['_nx_name'] for comm in part) for part in partition]\n",
    "    print(\"Used Leiden algorithm for community detection\")\n",
    "except ImportError:\n",
    "    print(\"leidenalg not available, using NetworkX greedy_modularity_communities (may be slow)\")\n",
    "    import networkx.algorithms.community as nx_comm\n",
    "    communities = nx_comm.greedy_modularity_communities(G_ud)  # Use undirected\n",
    "\n",
    "node_to_comm = {}\n",
    "for i, comm in enumerate(communities):\n",
    "    for node in comm:\n",
    "        node_to_comm[node] = i\n",
    "\n",
    "coherence = {}\n",
    "for node in G_ud.nodes():  # Use undirected for consistency\n",
    "    # e.g., coherence = fraction of node's neighbors in same community\n",
    "    neighbors = list(G_ud.neighbors(node))\n",
    "    if neighbors:\n",
    "        same_comm = sum(1 for n in neighbors if node_to_comm.get(n) == node_to_comm.get(node))\n",
    "        coherence[node] = same_comm / len(neighbors)\n",
    "    else:\n",
    "        coherence[node] = None\n",
    "print(f\"Computed coherence for {len(coherence)} nodes.\")\n",
    "\n",
    "# Save communities and coherence as parquet\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "OUTDIR = PROC/\"kec\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "comm_df = pd.DataFrame(list(node_to_comm.items()), columns=['node', 'community'])\n",
    "comm_df.to_parquet(OUTDIR/\"communities_leiden.parquet\")\n",
    "coh_df = pd.DataFrame(list(coherence.items()), columns=['node', 'coherence'])\n",
    "coh_df.to_parquet(OUTDIR/\"coherence.parquet\")\n",
    "print(f\"Saved communities to {OUTDIR/'communities_leiden.parquet'}\")\n",
    "print(f\"Saved coherence to {OUTDIR/'coherence.parquet'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05176ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:43.294415Z",
     "iopub.status.busy": "2025-09-02T12:25:43.294208Z",
     "iopub.status.idle": "2025-09-02T12:25:43.308767Z",
     "shell.execute_reply": "2025-09-02T12:25:43.308108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved KEC metrics for 7 nodes to data/processed/kec/metrics_en.csv\n",
      "Sample metrics:\n",
      "   node  entropy  degree  coherence  avg_curvature\n",
      "0   cat      1.0       2        0.5            0.0\n",
      "1  meow      0.0       1        1.0            0.0\n",
      "2   pet      0.0       2        0.5            0.0\n",
      "3   dog      1.0       2        1.0            0.0\n",
      "4  bark      0.0       1        1.0            0.0\n",
      "Saved KEC metrics as parquet to data/processed/kec/metrics_en.parquet\n"
     ]
    }
   ],
   "source": [
    "# Save the computed metrics\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Create output directory\n",
    "output_dir = str(PROC / 'kec')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Prepare data for saving\n",
    "metrics_data = []\n",
    "for node in G.nodes():\n",
    "    row = {\n",
    "        'node': node,\n",
    "        'entropy': entropy.get(node, None),\n",
    "        'degree': G.degree(node),\n",
    "        'coherence': coherence.get(node, None) if 'coherence' in locals() else None\n",
    "    }\n",
    "    # Add curvature for edges connected to this node (average or max)\n",
    "    node_curvatures = [curvature.get((node, neighbor), 0) for neighbor in G.neighbors(node)]\n",
    "    row['avg_curvature'] = sum(node_curvatures) / len(node_curvatures) if node_curvatures else 0\n",
    "    metrics_data.append(row)\n",
    "\n",
    "# Save to CSV\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "output_file = os.path.join(output_dir, f'metrics_{LANG}.csv')\n",
    "metrics_df.to_csv(output_file, index=False)\n",
    "print(f\"Saved KEC metrics for {len(metrics_data)} nodes to {output_file}\")\n",
    "print(f\"Sample metrics:\\n{metrics_df.head()}\")\n",
    "\n",
    "# Also save as parquet for QA\n",
    "from pathlib import Path\n",
    "OUTDIR = Path(output_dir)\n",
    "metrics_df.to_parquet(OUTDIR/f\"metrics_{LANG}.parquet\")\n",
    "print(f\"Saved KEC metrics as parquet to {OUTDIR/f'metrics_{LANG}.parquet'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b7195b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:43.310752Z",
     "iopub.status.busy": "2025-09-02T12:25:43.310504Z",
     "iopub.status.idle": "2025-09-02T12:25:43.338929Z",
     "shell.execute_reply": "2025-09-02T12:25:43.338296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_nodes': 7, 'kec_rows': 7, 'coverage_kec': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Alignment check across produced tables (safe)\n",
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "PROC=Path('data/processed')\n",
    "kec_path = PROC/'kec'/'metrics_en.csv'\n",
    "ent_path = PROC/'kec'/'entropy.parquet'\n",
    "coh_path = PROC/'kec'/'coherence.parquet'\n",
    "comm_path= PROC/'kec'/'communities_leiden.parquet'\n",
    "try:\n",
    "    df_kec = pd.read_csv(kec_path) if kec_path.exists() else pd.DataFrame()\n",
    "    df_ent = pd.read_parquet(ent_path) if ent_path.exists() else pd.DataFrame()\n",
    "    df_coh = pd.read_parquet(coh_path) if coh_path.exists() else pd.DataFrame()\n",
    "    df_com = pd.read_parquet(comm_path) if comm_path.exists() else pd.DataFrame()\n",
    "    n_nodes = int(len(set(df_ent.get('node', pd.Series())) | set(df_coh.get('node', pd.Series())) | set(df_com.get('node', pd.Series()))))\n",
    "    coverage_kec = (len(df_kec) / n_nodes) if n_nodes else np.nan\n",
    "    print({'n_nodes': n_nodes, 'kec_rows': int(len(df_kec)), 'coverage_kec': float(coverage_kec) if coverage_kec==coverage_kec else None})\n",
    "except Exception as e:\n",
    "    print('[warn] alignment check failed:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019604ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:43.341561Z",
     "iopub.status.busy": "2025-09-02T12:25:43.341355Z",
     "iopub.status.idle": "2025-09-02T12:25:43.399989Z",
     "shell.execute_reply": "2025-09-02T12:25:43.399166Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[warn] leidenalg unavailable; using NetworkX greedy modularity: No module named 'leidenalg'\n",
      "✓ coherence_null.parquet salvo\n",
      "Δcoherence (real - nulo): {'count': 7.0, 'mean': 0.0, 'std': 0.0, 'min': 0.0, '25%': 0.0, '50%': 0.0, '75%': 0.0, 'max': 0.0}\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx, random, pandas as pd\n",
    "from pathlib import Path\n",
    "random.seed(42)\n",
    "# Copy undirected graph\n",
    "assert 'G_ud' in globals(), 'G_ud indisponível — rode as células anteriores.'\n",
    "G_null = G_ud.copy()\n",
    "# Degree-preserving swap (bounded for safety)\n",
    "nswap = min(5 * G_null.number_of_edges(), 200000)\n",
    "try:\n",
    "    G_null = nx.double_edge_swap(G_null, nswap=nswap, max_tries=nswap*5, seed=42)\n",
    "except Exception as e:\n",
    "    print('Aviso: swap parcial:', e)\n",
    "# Community detection: prefer leidenalg if available, else NetworkX\n",
    "node_to_comm_null = {}\n",
    "try:\n",
    "    import igraph as ig, leidenalg as la\n",
    "    edges = [(u, v, G_null[u][v].get('weight',1.0)) for u, v in G_null.edges()]\n",
    "    g = ig.Graph.TupleList(edges, directed=False, edge_attrs=['weight'])\n",
    "    g.simplify(combine_edges={'weight':'sum'})\n",
    "    giant = g.clusters().giant()\n",
    "    part = la.find_partition(giant, la.RBConfigurationVertexPartition, weights='weight', resolution_parameter=1.0, seed=42)\n",
    "    node_ids = giant.vs['name']\n",
    "    membership = part.membership\n",
    "    node_to_comm_null = dict(zip(node_ids, membership))\n",
    "except Exception as e:\n",
    "    print('[warn] leidenalg unavailable; using NetworkX greedy modularity:', e)\n",
    "    import networkx.algorithms.community as nx_comm\n",
    "    communities = nx_comm.greedy_modularity_communities(G_null)\n",
    "    for i, comm in enumerate(communities):\n",
    "        for n in comm:\n",
    "            node_to_comm_null[n] = i\n",
    "# Coherence on null graph\n",
    "rows = []\n",
    "for node in G_null.nodes():\n",
    "    neigh = list(G_null.neighbors(node))\n",
    "    if not neigh:\n",
    "        coh = None\n",
    "    else:\n",
    "        same = sum(1 for n in neigh if node_to_comm_null.get(n) == node_to_comm_null.get(node))\n",
    "        coh = same/len(neigh)\n",
    "    rows.append((node, coh))\n",
    "coh_null = pd.DataFrame(rows, columns=['node','coherence_null'])\n",
    "coh_null.to_parquet(str(PROC/ 'kec' / 'coherence_null.parquet'), index=False)\n",
    "print('✓ coherence_null.parquet salvo')\n",
    "# Summary compare\n",
    "import pandas as pd\n",
    "coh_df = pd.read_parquet(str(PROC/ 'kec' / 'coherence.parquet'))\n",
    "cmp_df = coh_df.merge(coh_null, on='node', how='inner').dropna()\n",
    "delta = (cmp_df['coherence'] - cmp_df['coherence_null']).describe().to_dict()\n",
    "print('Δcoherence (real - nulo):', {k: round(v,4) if isinstance(v,(int,float)) else v for k,v in delta.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e90f9dd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:43.402773Z",
     "iopub.status.busy": "2025-09-02T12:25:43.402545Z",
     "iopub.status.idle": "2025-09-02T12:25:43.412787Z",
     "shell.execute_reply": "2025-09-02T12:25:43.412164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Rewrote data/processed/kec/metrics_en.csv with columns: ['token_norm', 'entropy', 'curvature', 'coherence']\n"
     ]
    }
   ],
   "source": [
    "# Finalize KEC metrics: ensure curvature alias and token_norm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "kec_path = Path(str(PROC/ 'kec' / 'metrics_en.csv'))\n",
    "if kec_path.exists():\n",
    "    df = pd.read_csv(kec_path)\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    # curvature alias\n",
    "    if 'avg_curvature' in df.columns and 'curvature' not in df.columns:\n",
    "        df = df.rename(columns={'avg_curvature':'curvature'})\n",
    "    # token_norm\n",
    "    def norm_token(s):\n",
    "        if not isinstance(s,str): return s\n",
    "        s = s.lower()\n",
    "        s = re.sub(r'[\\W_]+','',s)\n",
    "        return s\n",
    "    src = 'node' if 'node' in df.columns else ('word' if 'word' in df.columns else None)\n",
    "    if src and 'token_norm' not in df.columns:\n",
    "        df['token_norm'] = df[src].astype(str).map(norm_token)\n",
    "    # minimal required cols\n",
    "    need = [c for c in ['token_norm','entropy','curvature','coherence'] if c in df.columns]\n",
    "    if need:\n",
    "        df.to_csv(kec_path, index=False)\n",
    "        print(f\"[OK] Rewrote {kec_path} with columns: {need}\")\n",
    "    else:\n",
    "        print(\"[WARN] Required KEC columns missing; file left unchanged.\")\n",
    "else:\n",
    "    print(f\"[WARN] Missing {kec_path}; run Notebook 02 cells above to generate it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9124abc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-02T12:25:43.415973Z",
     "iopub.status.busy": "2025-09-02T12:25:43.415633Z",
     "iopub.status.idle": "2025-09-02T12:25:43.425706Z",
     "shell.execute_reply": "2025-09-02T12:25:43.424905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[v4.3] Rewrote metrics_en.csv with columns ['token_norm', 'entropy', 'curvature', 'coherence']\n"
     ]
    }
   ],
   "source": [
    "# v4.3 finalization: enforce KEC output schema\n",
    "from pathlib import Path\n",
    "import pandas as pd, re\n",
    "PROC=Path('data/processed'); KEC=PROC/'kec'; KEC.mkdir(parents=True, exist_ok=True)\n",
    "path=KEC/'metrics_en.csv'\n",
    "if path.exists():\n",
    "    df=pd.read_csv(path)\n",
    "    if 'curvature' not in df.columns and 'avg_curvature' in df.columns:\n",
    "        df=df.rename(columns={'avg_curvature':'curvature'})\n",
    "    if 'token_norm' not in df.columns:\n",
    "        def norm_token(s):\n",
    "            if not isinstance(s,str): return s\n",
    "            s=s.lower(); s=re.sub(r'[\\W_]+','',s); return s\n",
    "        src='token_norm' if 'token_norm' in df.columns else ('node' if 'node' in df.columns else ('word' if 'word' in df.columns else ('Word' if 'Word' in df.columns else None)))\n",
    "        if src:\n",
    "            df['token_norm']=df[src].astype(str).map(norm_token)\n",
    "    need=['token_norm','entropy','curvature','coherence']\n",
    "    for c in need:\n",
    "        if c not in df.columns:\n",
    "            df[c]=pd.NA\n",
    "    df=df[need]\n",
    "    df.to_csv(path, index=False)\n",
    "    print('[v4.3] Rewrote metrics_en.csv with columns', need)\n",
    "else:\n",
    "    print('[v4.3] KEC file not found; skip schema finalization')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcs-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
